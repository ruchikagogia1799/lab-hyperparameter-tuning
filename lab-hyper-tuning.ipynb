{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# LAB | Hyperparameter Tuning"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Load the data**\n",
    "\n",
    "Finally step in order to maximize the performance on your Spaceship Titanic model.\n",
    "\n",
    "The data can be found here:\n",
    "\n",
    "https://raw.githubusercontent.com/data-bootcamp-v4/data/main/spaceship_titanic.csv\n",
    "\n",
    "Metadata\n",
    "\n",
    "https://github.com/data-bootcamp-v4/data/blob/main/spaceship_titanic.md"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "So far we've been training and evaluating models with default values for hyperparameters.\n",
    "\n",
    "Today we will perform the same feature engineering as before, and then compare the best working models you got so far, but now fine tuning it's hyperparameters."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Libraries\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>PassengerId</th>\n",
       "      <th>HomePlanet</th>\n",
       "      <th>CryoSleep</th>\n",
       "      <th>Cabin</th>\n",
       "      <th>Destination</th>\n",
       "      <th>Age</th>\n",
       "      <th>VIP</th>\n",
       "      <th>RoomService</th>\n",
       "      <th>FoodCourt</th>\n",
       "      <th>ShoppingMall</th>\n",
       "      <th>Spa</th>\n",
       "      <th>VRDeck</th>\n",
       "      <th>Name</th>\n",
       "      <th>Transported</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0001_01</td>\n",
       "      <td>Europa</td>\n",
       "      <td>False</td>\n",
       "      <td>B/0/P</td>\n",
       "      <td>TRAPPIST-1e</td>\n",
       "      <td>39.0</td>\n",
       "      <td>False</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>Maham Ofracculy</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0002_01</td>\n",
       "      <td>Earth</td>\n",
       "      <td>False</td>\n",
       "      <td>F/0/S</td>\n",
       "      <td>TRAPPIST-1e</td>\n",
       "      <td>24.0</td>\n",
       "      <td>False</td>\n",
       "      <td>109.0</td>\n",
       "      <td>9.0</td>\n",
       "      <td>25.0</td>\n",
       "      <td>549.0</td>\n",
       "      <td>44.0</td>\n",
       "      <td>Juanna Vines</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0003_01</td>\n",
       "      <td>Europa</td>\n",
       "      <td>False</td>\n",
       "      <td>A/0/S</td>\n",
       "      <td>TRAPPIST-1e</td>\n",
       "      <td>58.0</td>\n",
       "      <td>True</td>\n",
       "      <td>43.0</td>\n",
       "      <td>3576.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>6715.0</td>\n",
       "      <td>49.0</td>\n",
       "      <td>Altark Susent</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0003_02</td>\n",
       "      <td>Europa</td>\n",
       "      <td>False</td>\n",
       "      <td>A/0/S</td>\n",
       "      <td>TRAPPIST-1e</td>\n",
       "      <td>33.0</td>\n",
       "      <td>False</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1283.0</td>\n",
       "      <td>371.0</td>\n",
       "      <td>3329.0</td>\n",
       "      <td>193.0</td>\n",
       "      <td>Solam Susent</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0004_01</td>\n",
       "      <td>Earth</td>\n",
       "      <td>False</td>\n",
       "      <td>F/1/S</td>\n",
       "      <td>TRAPPIST-1e</td>\n",
       "      <td>16.0</td>\n",
       "      <td>False</td>\n",
       "      <td>303.0</td>\n",
       "      <td>70.0</td>\n",
       "      <td>151.0</td>\n",
       "      <td>565.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>Willy Santantines</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  PassengerId HomePlanet CryoSleep  Cabin  Destination   Age    VIP  \\\n",
       "0     0001_01     Europa     False  B/0/P  TRAPPIST-1e  39.0  False   \n",
       "1     0002_01      Earth     False  F/0/S  TRAPPIST-1e  24.0  False   \n",
       "2     0003_01     Europa     False  A/0/S  TRAPPIST-1e  58.0   True   \n",
       "3     0003_02     Europa     False  A/0/S  TRAPPIST-1e  33.0  False   \n",
       "4     0004_01      Earth     False  F/1/S  TRAPPIST-1e  16.0  False   \n",
       "\n",
       "   RoomService  FoodCourt  ShoppingMall     Spa  VRDeck               Name  \\\n",
       "0          0.0        0.0           0.0     0.0     0.0    Maham Ofracculy   \n",
       "1        109.0        9.0          25.0   549.0    44.0       Juanna Vines   \n",
       "2         43.0     3576.0           0.0  6715.0    49.0      Altark Susent   \n",
       "3          0.0     1283.0         371.0  3329.0   193.0       Solam Susent   \n",
       "4        303.0       70.0         151.0   565.0     2.0  Willy Santantines   \n",
       "\n",
       "   Transported  \n",
       "0        False  \n",
       "1         True  \n",
       "2        False  \n",
       "3        False  \n",
       "4         True  "
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "spaceship = pd.read_csv(\"https://raw.githubusercontent.com/data-bootcamp-v4/data/main/spaceship_titanic.csv\")\n",
    "spaceship.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now perform the same as before:\n",
    "- Feature Scaling\n",
    "- Feature Selection\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Scaled shapes : (5284, 19) (1322, 19)\n",
      "Selected top-10 features: ['RoomService', 'Spa', 'VRDeck', 'HomePlanet_Europa', 'CryoSleep_True', 'Destination_TRAPPIST-1e', 'Deck_B', 'Deck_C', 'Deck_E', 'Deck_F']\n",
      "Final shapes  : (5284, 10) (1322, 10)\n"
     ]
    }
   ],
   "source": [
    "#your code here\n",
    "# --- Feature Scaling + Feature Selection ---\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.feature_selection import SelectKBest, f_classif\n",
    "import pandas as pd\n",
    "\n",
    "# 1) Minimal prep (skip if you already have X, y)\n",
    "df = spaceship.dropna().reset_index(drop=True).copy()\n",
    "df[\"Deck\"] = df[\"Cabin\"].str.split(\"/\").str[0]\n",
    "df = df.drop(columns=[\"PassengerId\", \"Name\", \"Cabin\"], errors=\"ignore\")\n",
    "\n",
    "df[\"Transported\"] = df[\"Transported\"].astype(int)\n",
    "bool_cols = df.select_dtypes(include=\"bool\").columns\n",
    "df[bool_cols] = df[bool_cols].astype(int)\n",
    "\n",
    "X = pd.get_dummies(df.drop(columns=\"Transported\"), drop_first=True)\n",
    "y = df[\"Transported\"]\n",
    "\n",
    "# 2) Train/test split (if not already split)\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    X, y, test_size=0.20, random_state=42, stratify=y\n",
    ")\n",
    "\n",
    "# 3) Feature Scaling (fit on train, apply to test)\n",
    "scaler = StandardScaler(with_mean=False)  # safe for sparse one-hots\n",
    "X_train_s = scaler.fit_transform(X_train)\n",
    "X_test_s  = scaler.transform(X_test)\n",
    "\n",
    "# 4) Feature Selection (top-k by ANOVA F)\n",
    "k = min(10, X_train.shape[1])            # choose k <= #features\n",
    "selector = SelectKBest(score_func=f_classif, k=k)\n",
    "X_train_sel = selector.fit_transform(X_train_s, y_train)\n",
    "X_test_sel  = selector.transform(X_test_s)\n",
    "\n",
    "selected_features = X.columns[selector.get_support()]\n",
    "\n",
    "print(\"Scaled shapes :\", X_train_s.shape, X_test_s.shape)\n",
    "print(f\"Selected top-{k} features:\", selected_features.tolist())\n",
    "print(\"Final shapes  :\", X_train_sel.shape, X_test_sel.shape)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Now let's use the best model we got so far in order to see how it can improve when we fine tune it's hyperparameters."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\ruchi\\anaconda3\\Lib\\site-packages\\joblib\\externals\\loky\\backend\\context.py:136: UserWarning: Could not find the number of physical cores for the following reason:\n",
      "[WinError 2] The system cannot find the file specified\n",
      "Returning the number of logical cores instead. You can silence this warning by setting LOKY_MAX_CPU_COUNT to the number of cores you want to use.\n",
      "  warnings.warn(\n",
      "  File \"c:\\Users\\ruchi\\anaconda3\\Lib\\site-packages\\joblib\\externals\\loky\\backend\\context.py\", line 257, in _count_physical_cores\n",
      "    cpu_info = subprocess.run(\n",
      "               ^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\ruchi\\anaconda3\\Lib\\subprocess.py\", line 548, in run\n",
      "    with Popen(*popenargs, **kwargs) as process:\n",
      "         ^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\ruchi\\anaconda3\\Lib\\subprocess.py\", line 1026, in __init__\n",
      "    self._execute_child(args, executable, preexec_fn, close_fds,\n",
      "  File \"c:\\Users\\ruchi\\anaconda3\\Lib\\subprocess.py\", line 1538, in _execute_child\n",
      "    hp, ht, pid, tid = _winapi.CreateProcess(executable, args,\n",
      "                       ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "=== HistGradientBoosting (fine-tuned) ===\n",
      "Best params: {'l2_regularization': 0.00032163086173926544, 'learning_rate': 0.04401232738598694, 'max_depth': 4, 'max_iter': 487, 'max_leaf_nodes': 209, 'min_samples_leaf': 58}\n",
      "CV best AUC: 0.8758\n",
      "Test AUC   : 0.8705\n",
      "Test Acc   : 0.7821\n",
      "Confusion matrix:\n",
      " [[457 199]\n",
      " [ 89 577]]\n",
      "              precision    recall  f1-score      support\n",
      "0              0.836996  0.696646  0.760399   656.000000\n",
      "1              0.743557  0.866366  0.800277   666.000000\n",
      "accuracy       0.782148  0.782148  0.782148     0.782148\n",
      "macro avg      0.790277  0.781506  0.780338  1322.000000\n",
      "weighted avg   0.789923  0.782148  0.780489  1322.000000\n",
      "\n",
      "Optimal threshold by Youden J: 0.560\n",
      "Confusion matrix @ optimal thr:\n",
      " [[491 165]\n",
      " [113 553]]\n",
      "              precision    recall  f1-score      support\n",
      "0              0.812914  0.748476  0.779365   656.000000\n",
      "1              0.770195  0.830330  0.799133   666.000000\n",
      "accuracy       0.789713  0.789713  0.789713     0.789713\n",
      "macro avg      0.791554  0.789403  0.789249  1322.000000\n",
      "weighted avg   0.791393  0.789713  0.789324  1322.000000\n"
     ]
    }
   ],
   "source": [
    "#your code here\n",
    "# === Fine-tune the current best model: HistGradientBoosting ===\n",
    "import os\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "from sklearn.ensemble import HistGradientBoostingClassifier\n",
    "from sklearn.model_selection import RandomizedSearchCV, StratifiedKFold\n",
    "from sklearn.metrics import accuracy_score, roc_auc_score, classification_report, confusion_matrix, roc_curve\n",
    "\n",
    "# Use your selected features if available; else fall back to full split\n",
    "try:\n",
    "    X_tr, X_te = X_train_sel, X_test_sel\n",
    "except NameError:\n",
    "    X_tr, X_te = X_train, X_test\n",
    "y_tr, y_te = y_train, y_test\n",
    "\n",
    "rng = 42\n",
    "n_jobs = min(8, os.cpu_count() or 1)\n",
    "\n",
    "# Baseline from before (good starting point)\n",
    "hgb_base = HistGradientBoostingClassifier(\n",
    "    learning_rate=0.1,\n",
    "    max_leaf_nodes=63,\n",
    "    min_samples_leaf=20,\n",
    "    max_iter=300,\n",
    "    early_stopping=True,\n",
    "    l2_regularization=0.1,\n",
    "    random_state=rng\n",
    ")\n",
    "\n",
    "# Randomized hyperparameter search (wider space than before)\n",
    "try:\n",
    "    from scipy.stats import loguniform, randint, uniform\n",
    "    param_dist = {\n",
    "        \"learning_rate\": loguniform(1e-3, 3e-1),\n",
    "        \"max_iter\": randint(150, 500),\n",
    "        \"max_leaf_nodes\": randint(16, 256),\n",
    "        \"max_depth\": randint(3, 12),        # None not supported in randint; we’ll allow deep trees via larger leaf nodes\n",
    "        \"min_samples_leaf\": randint(5, 200),\n",
    "        \"l2_regularization\": loguniform(1e-4, 10),\n",
    "    }\n",
    "    search = RandomizedSearchCV(\n",
    "        estimator=hgb_base,\n",
    "        param_distributions=param_dist,\n",
    "        n_iter=60,\n",
    "        scoring=\"roc_auc\",\n",
    "        cv=StratifiedKFold(n_splits=5, shuffle=True, random_state=rng),\n",
    "        n_jobs=n_jobs,\n",
    "        random_state=rng,\n",
    "        refit=True,\n",
    "        verbose=0,\n",
    "    )\n",
    "except Exception:\n",
    "    # Fallback to a compact grid if scipy isn't available\n",
    "    param_grid = {\n",
    "        \"learning_rate\": [0.03, 0.05, 0.08, 0.1],\n",
    "        \"max_iter\": [200, 300, 400],\n",
    "        \"max_leaf_nodes\": [31, 63, 127, 255],\n",
    "        \"max_depth\": [4, 6, 8, 10],\n",
    "        \"min_samples_leaf\": [10, 20, 50, 100],\n",
    "        \"l2_regularization\": [0.0, 0.1, 1.0],\n",
    "    }\n",
    "    from sklearn.model_selection import GridSearchCV\n",
    "    search = GridSearchCV(\n",
    "        estimator=hgb_base,\n",
    "        param_grid=param_grid,\n",
    "        scoring=\"roc_auc\",\n",
    "        cv=StratifiedKFold(n_splits=5, shuffle=True, random_state=rng),\n",
    "        n_jobs=n_jobs,\n",
    "        refit=True,\n",
    "        verbose=0,\n",
    "    )\n",
    "\n",
    "# Fit search\n",
    "search.fit(X_tr, y_tr)\n",
    "best_hgb = search.best_estimator_\n",
    "\n",
    "# ---- Evaluation helpers ----\n",
    "def evaluate(name, clf, X_te, y_te):\n",
    "    proba = clf.predict_proba(X_te)[:, 1]\n",
    "    pred  = clf.predict(X_te)\n",
    "    acc = accuracy_score(y_te, pred)\n",
    "    auc = roc_auc_score(y_te, proba)\n",
    "    print(f\"\\n=== {name} ===\")\n",
    "    print(\"Best params:\", search.best_params_)\n",
    "    print(f\"CV best AUC: {search.best_score_:.4f}\")\n",
    "    print(f\"Test AUC   : {auc:.4f}\")\n",
    "    print(f\"Test Acc   : {acc:.4f}\")\n",
    "    print(\"Confusion matrix:\\n\", confusion_matrix(y_te, pred))\n",
    "    print(pd.DataFrame(classification_report(y_te, pred, digits=4, output_dict=True)).T)\n",
    "    return proba, pred\n",
    "\n",
    "proba, pred = evaluate(\"HistGradientBoosting (fine-tuned)\", best_hgb, X_te, y_te)\n",
    "\n",
    "# ---- Optional: threshold tuning (maximize Youden’s J) ----\n",
    "fpr, tpr, thr = roc_curve(y_te, proba)\n",
    "j_idx = (tpr - fpr).argmax()\n",
    "best_thr = thr[j_idx]\n",
    "pred_thr = (proba >= best_thr).astype(int)\n",
    "\n",
    "print(f\"\\nOptimal threshold by Youden J: {best_thr:.3f}\")\n",
    "print(\"Confusion matrix @ optimal thr:\\n\", confusion_matrix(y_te, pred_thr))\n",
    "print(pd.DataFrame(classification_report(y_te, pred_thr, digits=4, output_dict=True)).T)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Evaluate your model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy : 0.7821 (baseline: 0.5038)\n",
      "ROC AUC  : 0.8705\n",
      "Confusion matrix:\n",
      " [[457 199]\n",
      " [ 89 577]]\n",
      "              precision    recall  f1-score      support\n",
      "0              0.836996  0.696646  0.760399   656.000000\n",
      "1              0.743557  0.866366  0.800277   666.000000\n",
      "accuracy       0.782148  0.782148  0.782148     0.782148\n",
      "macro avg      0.790277  0.781506  0.780338  1322.000000\n",
      "weighted avg   0.789923  0.782148  0.780489  1322.000000\n"
     ]
    }
   ],
   "source": [
    "#your code here\n",
    "from sklearn.metrics import accuracy_score, roc_auc_score, confusion_matrix, classification_report\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "# pick the fitted model (adjust if your variable name differs)\n",
    "clf = best_hgb  # or: search.best_estimator_\n",
    "\n",
    "# predictions\n",
    "y_pred  = clf.predict(X_te)\n",
    "y_proba = clf.predict_proba(X_te)[:, 1]\n",
    "\n",
    "# core metrics\n",
    "acc = accuracy_score(y_te, y_pred)\n",
    "auc = roc_auc_score(y_te, y_proba)\n",
    "baseline = max(np.mean(y_te == 0), np.mean(y_te == 1))  # majority-class baseline\n",
    "\n",
    "print(f\"Accuracy : {acc:.4f} (baseline: {baseline:.4f})\")\n",
    "print(f\"ROC AUC  : {auc:.4f}\")\n",
    "print(\"Confusion matrix:\\n\", confusion_matrix(y_te, y_pred))\n",
    "print(pd.DataFrame(classification_report(y_te, y_pred, digits=4, output_dict=True)).T)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Grid/Random Search**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For this lab we will use Grid Search."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Define hyperparameters to fine tune."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best params: {'l2_regularization': 0.0007444441903453075, 'learning_rate': 0.05146791283102272, 'max_bins': 166, 'max_depth': 4, 'max_iter': 559, 'max_leaf_nodes': 144, 'min_samples_leaf': 15, 'validation_fraction': 0.1}\n",
      "CV best AUC: 0.8753605700976628\n",
      "Test AUC   : 0.8702288416465246\n"
     ]
    }
   ],
   "source": [
    "#your code here\n",
    "from sklearn.ensemble import HistGradientBoostingClassifier\n",
    "from sklearn.model_selection import RandomizedSearchCV, StratifiedKFold\n",
    "from scipy.stats import loguniform, randint\n",
    "import os\n",
    "\n",
    "hgb = HistGradientBoostingClassifier(\n",
    "    early_stopping=True, random_state=42\n",
    ")\n",
    "\n",
    "param_dist = {\n",
    "    \"learning_rate\":     loguniform(1e-3, 3e-1),\n",
    "    \"max_iter\":          randint(200, 600),\n",
    "    \"max_leaf_nodes\":    randint(16, 256),\n",
    "    \"max_depth\":         randint(3, 12),      # optional alongside max_leaf_nodes\n",
    "    \"min_samples_leaf\":  randint(5, 200),\n",
    "    \"l2_regularization\": loguniform(1e-4, 10),\n",
    "    \"max_bins\":          randint(128, 255),\n",
    "    \"validation_fraction\": [0.1, 0.15, 0.2],\n",
    "}\n",
    "\n",
    "cv = StratifiedKFold(n_splits=5, shuffle=True, random_state=42)\n",
    "rs = RandomizedSearchCV(\n",
    "    hgb, param_distributions=param_dist, n_iter=60,\n",
    "    scoring=\"roc_auc\", cv=cv, n_jobs=min(8, os.cpu_count() or 1),\n",
    "    random_state=42, refit=True, verbose=0\n",
    ")\n",
    "rs.fit(X_tr, y_tr)\n",
    "best_hgb = rs.best_estimator_\n",
    "print(\"Best params:\", rs.best_params_)\n",
    "print(\"CV best AUC:\", rs.best_score_)\n",
    "print(\"Test AUC   :\", roc_auc_score(y_te, best_hgb.predict_proba(X_te)[:,1]))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Run Grid Search"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best params: {'l2_regularization': 1.0, 'learning_rate': 0.05, 'max_depth': None, 'max_iter': 200, 'max_leaf_nodes': 31, 'min_samples_leaf': 20, 'validation_fraction': 0.1}\n",
      "CV best AUC: 0.8753\n",
      "Test Accuracy: 0.7784\n",
      "Test ROC AUC : 0.8654\n",
      "Confusion matrix:\n",
      " [[461 195]\n",
      " [ 98 568]]\n",
      "              precision    recall  f1-score      support\n",
      "0              0.824687  0.702744  0.758848   656.000000\n",
      "1              0.744430  0.852853  0.794962   666.000000\n",
      "accuracy       0.778366  0.778366  0.778366     0.778366\n",
      "macro avg      0.784558  0.777798  0.776905  1322.000000\n",
      "weighted avg   0.784255  0.778366  0.777041  1322.000000\n"
     ]
    }
   ],
   "source": [
    "# Run a GRID SEARCH for the best HistGradientBoostingClassifier\n",
    "\n",
    "import os\n",
    "import pandas as pd\n",
    "from sklearn.ensemble import HistGradientBoostingClassifier\n",
    "from sklearn.model_selection import GridSearchCV, StratifiedKFold\n",
    "from sklearn.metrics import accuracy_score, roc_auc_score, confusion_matrix, classification_report\n",
    "\n",
    "# Use selected features if available; else fall back to full split\n",
    "try:\n",
    "    X_tr, X_te = X_train_sel, X_test_sel\n",
    "except NameError:\n",
    "    X_tr, X_te = X_train, X_test\n",
    "y_tr, y_te = y_train, y_test\n",
    "\n",
    "rng = 42\n",
    "n_jobs = min(8, os.cpu_count() or 1)\n",
    "\n",
    "hgb = HistGradientBoostingClassifier(\n",
    "    early_stopping=True,\n",
    "    random_state=rng\n",
    ")\n",
    "\n",
    "param_grid = {\n",
    "    \"learning_rate\":     [0.03, 0.05, 0.08, 0.1],\n",
    "    \"max_iter\":          [200, 300, 400],\n",
    "    \"max_leaf_nodes\":    [31, 63, 127],\n",
    "    \"min_samples_leaf\":  [10, 20, 50, 100],\n",
    "    \"l2_regularization\": [0.0, 0.1, 1.0],\n",
    "    \"max_depth\":         [None, 6, 10],\n",
    "    \"validation_fraction\":[0.1, 0.2],\n",
    "}\n",
    "\n",
    "cv = StratifiedKFold(n_splits=5, shuffle=True, random_state=rng)\n",
    "\n",
    "gs = GridSearchCV(\n",
    "    estimator=hgb,\n",
    "    param_grid=param_grid,\n",
    "    scoring=\"roc_auc\",\n",
    "    cv=cv,\n",
    "    n_jobs=n_jobs,\n",
    "    refit=True,\n",
    "    verbose=0\n",
    ")\n",
    "\n",
    "gs.fit(X_tr, y_tr)\n",
    "best_hgb = gs.best_estimator_\n",
    "\n",
    "print(\"Best params:\", gs.best_params_)\n",
    "print(\"CV best AUC:\", f\"{gs.best_score_:.4f}\")\n",
    "\n",
    "# ---- Evaluate on test set ----\n",
    "y_pred  = best_hgb.predict(X_te)\n",
    "y_proba = best_hgb.predict_proba(X_te)[:, 1]\n",
    "\n",
    "print(f\"Test Accuracy: {accuracy_score(y_te, y_pred):.4f}\")\n",
    "print(f\"Test ROC AUC : {roc_auc_score(y_te, y_proba):.4f}\")\n",
    "print(\"Confusion matrix:\\n\", confusion_matrix(y_te, y_pred))\n",
    "print(pd.DataFrame(classification_report(y_te, y_pred, digits=4, output_dict=True)).T)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Evaluate your model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy : 0.7784  (baseline: 0.5038)\n",
      "ROC AUC  : 0.8654\n",
      "Precision: 0.7444 | Recall: 0.8529 | F1: 0.7950\n",
      "\n",
      "Confusion matrix:\n",
      " [[461 195]\n",
      " [ 98 568]]\n",
      "\n",
      "Classification report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0     0.8247    0.7027    0.7588       656\n",
      "           1     0.7444    0.8529    0.7950       666\n",
      "\n",
      "    accuracy                         0.7784      1322\n",
      "   macro avg     0.7846    0.7778    0.7769      1322\n",
      "weighted avg     0.7843    0.7784    0.7770      1322\n",
      "\n",
      "\n",
      "Optimal threshold by Youden J: 0.577\n",
      "Confusion @ optimal thr:\n",
      " [[516 140]\n",
      " [138 528]]\n",
      "              precision    recall  f1-score      support\n",
      "0              0.788991  0.786585  0.787786   656.000000\n",
      "1              0.790419  0.792793  0.791604   666.000000\n",
      "accuracy       0.789713  0.789713  0.789713     0.789713\n",
      "macro avg      0.789705  0.789689  0.789695  1322.000000\n",
      "weighted avg   0.789710  0.789713  0.789710  1322.000000\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import (\n",
    "    accuracy_score, roc_auc_score, confusion_matrix,\n",
    "    classification_report, precision_recall_fscore_support\n",
    ")\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "# Use the fitted best model from your GridSearch\n",
    "clf = best_hgb  # if you kept the name; else: clf = gs.best_estimator_\n",
    "\n",
    "# Predict\n",
    "y_pred  = clf.predict(X_te)\n",
    "y_proba = clf.predict_proba(X_te)[:, 1]\n",
    "\n",
    "# Core metrics\n",
    "acc = accuracy_score(y_te, y_pred)\n",
    "auc = roc_auc_score(y_te, y_proba)\n",
    "prec, rec, f1, _ = precision_recall_fscore_support(y_te, y_pred, average=\"binary\")\n",
    "cm = confusion_matrix(y_te, y_pred)\n",
    "baseline = max(np.mean(y_te == 0), np.mean(y_te == 1))  # majority-class baseline\n",
    "\n",
    "print(f\"Accuracy : {acc:.4f}  (baseline: {baseline:.4f})\")\n",
    "print(f\"ROC AUC  : {auc:.4f}\")\n",
    "print(f\"Precision: {prec:.4f} | Recall: {rec:.4f} | F1: {f1:.4f}\")\n",
    "print(\"\\nConfusion matrix:\\n\", cm)\n",
    "print(\"\\nClassification report:\\n\",\n",
    "      classification_report(y_te, y_pred, digits=4))\n",
    "\n",
    "# Optional: threshold tuning (maximize Youden’s J for better recall/precision trade-off)\n",
    "from sklearn.metrics import roc_curve\n",
    "fpr, tpr, thr = roc_curve(y_te, y_proba)\n",
    "j_idx = (tpr - fpr).argmax()\n",
    "best_thr = thr[j_idx]\n",
    "y_pred_thr = (y_proba >= best_thr).astype(int)\n",
    "print(f\"\\nOptimal threshold by Youden J: {best_thr:.3f}\")\n",
    "print(\"Confusion @ optimal thr:\\n\", confusion_matrix(y_te, y_pred_thr))\n",
    "print(pd.DataFrame(classification_report(y_te, y_pred_thr, digits=4, output_dict=True)).T)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
